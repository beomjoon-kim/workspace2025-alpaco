# app_chat_dashboard.py
# ì—…ë¡œë“œ ì˜ˆì œ(01~05)ì˜ í¬ì¸íŠ¸ë¥¼ í•˜ë‚˜ì˜ Streamlit ì•±ìœ¼ë¡œ í†µí•©í•œ ì‹¤ìŠµ ì½”ë“œ
# - dotenvë¡œ í‚¤ ê´€ë¦¬, Responses API(ë¹„-ìŠ¤íŠ¸ë¦¬ë°), íƒ­/ì‚¬ì´ë“œë°”/ì°¨íŠ¸/ë¡œê·¸/ë‹¤ìš´ë¡œë“œ í¬í•¨

import os, time, io, textwrap, datetime as dt
import pandas as pd
import plotly.graph_objects as go
import streamlit as st
from dotenv import load_dotenv, find_dotenv
from openai import OpenAI

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 0) í™˜ê²½ì„¤ì •: dotenv â†’ OPENAI_API_KEY
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv(find_dotenv())
OPENAI_API_KEY = (os.getenv("OPENAI_API_KEY") or "").strip()

st.set_page_config(page_title="Chat + Logs + Charts", page_icon="ğŸ’¬", layout="wide")
st.title("ğŸ’¬ Chat Dashboard (Streamlit x OpenAI)")

if not OPENAI_API_KEY or not OPENAI_API_KEY.startswith("sk-"):
    st.error("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

client = OpenAI(api_key=OPENAI_API_KEY)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1) Session State ì´ˆê¸°í™”
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "messages" not in st.session_state:
    st.session_state.messages = []   # ì±„íŒ… ë§í’ì„  í‘œì‹œìš©(ê°„ë‹¨)
if "logs" not in st.session_state:
    # ëŒ€í™”/ì¸¡ì •ì¹˜ ëˆ„ì  ë¡œê·¸(DataFrameìš©)
    st.session_state.logs = []       # [{ts, model, domain, temp, chars_in, chars_out, t_ms, tok_in, tok_out, answer}]
if "sys_prompt" not in st.session_state:
    st.session_state.sys_prompt = textwrap.dedent("""
    You are a helpful assistant.
    - ë‹µì„ ëª¨ë¥´ë©´ ëª¨ë¥¸ë‹¤ê³  ë§í•©ë‹ˆë‹¤.
    - ë¶ˆí™•ì‹¤í•œ ì •ë³´ëŠ” ì¶”ì¸¡í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    - ê°„ê²°í•˜ê³  ë‹¨ê³„ì ìœ¼ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤.
    """)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2) ì‚¬ì´ë“œë°”(05_layout / 04_input widget)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.subheader("âš™ï¸ Settings")
    # ëª¨ë¸ì€ ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œ ê²ƒë§Œ ë…¸ì¶œ
    model = st.selectbox(
        "Model",
        options=["gpt-4o-mini", "gpt-4o", "gpt-4.1", "gpt-3.5-turbo"],
        index=0,
    )
    temperature = st.slider("Temperature", 0.0, 1.0, 0.3, 0.1)
    domain = st.radio("Domain(ì—­í•  í”„ë¦¬ì…‹)", ["ì¼ë°˜", "ì—¬í–‰ì¶”ì²œ", "ì‹ë‹¨ì½”ì¹˜", "í•™ìŠµíŠœí„°"], index=0, horizontal=False)
    st.divider()
    st.caption("ğŸ”’ API Key: í™˜ê²½ë³€ìˆ˜(.env) ë¡œë“œë¨")
    st.caption("â€» í‚¤ ê°’ì€ í™”ë©´ì— ë…¸ì¶œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

# ë„ë©”ì¸ í”„ë¦¬ì…‹ â†’ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ë°˜ì˜
DOMAIN_GUIDE = {
    "ì¼ë°˜": "",
    "ì—¬í–‰ì¶”ì²œ": "ì—¬í–‰í”Œë˜ë„ˆ ì—­í• ë¡œ, 2~3ê°œ í›„ë³´ ì¼ì •ê³¼ ì¥ë‹¨ì ì„ ì œì‹œí•©ë‹ˆë‹¤.",
    "ì‹ë‹¨ì½”ì¹˜": "ì˜ì–‘ ì½”ì¹˜ ì—­í• ë¡œ, ì•Œë ˆë¥´ê¸°/ì„ í˜¸ë¥¼ ì§ˆë¬¸í•˜ê³  1ì¼ ì‹ë‹¨ì„ ì œì‹œí•©ë‹ˆë‹¤.",
    "í•™ìŠµíŠœí„°": "í•™ìŠµ íŠœí„° ì—­í• ë¡œ, ì˜ˆì œâ†’ì„¤ëª…â†’í€´ì¦ˆâ†’ìš”ì•½ ìˆœì„œë¡œ ê°€ë¥´ì¹©ë‹ˆë‹¤.",
}
sys_prompt = st.session_state.sys_prompt + ("\n" + DOMAIN_GUIDE.get(domain, ""))

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3) ìƒë‹¨ ì•ˆë‚´(01_text: ë§ˆí¬ë‹¤ìš´/ì½”ë“œ/ìˆ˜ì‹ â†’ ê°€ì´ë“œ/ìƒ˜í”Œ)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.expander("ğŸ“˜ ì‹œìŠ¤í…œ ê°€ì´ë“œ & ìƒ˜í”Œ í‘œì‹œ (01_text ì‘ìš©)", expanded=False):
    st.markdown("""
    - **ì—­í• (System Prompt)**ì€ ì¢Œì¸¡ Domain ì„ íƒì— ë”°ë¼ ë³´ê°•ë©ë‹ˆë‹¤.
    - `st.markdown`, `st.code`, `st.latex` ì‚¬ìš© ì˜ˆì‹œë¥¼ ì•„ë˜ì— ë°°ì¹˜í–ˆìŠµë‹ˆë‹¤.
    """)
    st.code(
        "def few_shot_rule():\n    return 'ê°„ê²°í•˜ê²Œ, ë‹¨ê³„ë³„ë¡œ, ì˜ˆì‹œì™€ í•¨ê»˜ ì„¤ëª…'\n",
        language="python",
    )
    st.latex(r"x=\frac{-b\pm\sqrt{b^2-4ac}}{2a}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4) íƒ­ êµ¬ì„±(05_layout): Chat / Logs / Charts
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
tab_chat, tab_logs, tab_charts = st.tabs(["ğŸ’¬ Chat", "ğŸ§¾ Logs", "ğŸ“ˆ Charts"])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4-1) Chat íƒ­
#   - ì¢Œ: ëŒ€í™”ì°½(03: ì—†ìŒ), ìš°: í†µê³„/ë„ì›€ë§ ì»¬ëŸ¼(02_dataì˜ metric/json ì‘ìš©)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with tab_chat:
    col_left, col_right = st.columns([2, 1])

    with col_left:
        st.subheader("ëŒ€í™”")
        # ì´ì „ ë©”ì‹œì§€ ì¶œë ¥
        for m in st.session_state.messages:
            with st.chat_message(m["role"]):
                st.markdown(m["content"])

        # ì…ë ¥ì°½
        if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”"):
            # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            # OpenAI í˜¸ì¶œ (Responses API, ë¹„-ìŠ¤íŠ¸ë¦¬ë°)
            start = time.perf_counter()
            try:
                # ê°„ë‹¨ ë¬¸ìì—´ í•©ì„± ì…ë ¥(ResponsesëŠ” ë¬¸ìì—´ input í—ˆìš©)
                composed = f"[SYSTEM]\n{sys_prompt}\n\n[USER]\n{prompt}"
                resp = client.responses.create(
                    model=model,
                    input=composed,
                    temperature=temperature,
                )
                # í…ìŠ¤íŠ¸/ì‚¬ìš©ëŸ‰ ì•ˆì „ ì¶”ì¶œ
                answer = getattr(resp, "output_text", None) or str(resp)
                usage = getattr(resp, "usage", None)

                dur_ms = int((time.perf_counter() - start) * 1000)
                tokens_in = tokens_out = None
                if usage:
                    # ê°ì²´/ë”•ì…”ë„ˆë¦¬ í˜¸í™˜ ì²˜ë¦¬
                    tokens_in = getattr(usage, "input_tokens", None) or (usage.get("input_tokens") if isinstance(usage, dict) else None)
                    tokens_out = getattr(usage, "output_tokens", None) or (usage.get("output_tokens") if isinstance(usage, dict) else None)

                # ì–´ì‹œìŠ¤í„´íŠ¸ ë§í’ì„ 
                with st.chat_message("assistant"):
                    st.markdown(answer)

                # ë©”ì‹œì§€/ë¡œê·¸ ì ì¬
                st.session_state.messages.append({"role": "assistant", "content": answer})
                st.session_state.logs.append({
                    "ts": dt.datetime.now().isoformat(timespec="seconds"),
                    "model": model,
                    "domain": domain,
                    "temp": temperature,
                    "chars_in": len(prompt),
                    "chars_out": len(answer),
                    "t_ms": dur_ms,
                    "tok_in": tokens_in,
                    "tok_out": tokens_out,
                    "answer": answer,
                    "question": prompt,
                })

            except Exception as e:
                with st.chat_message("assistant"):
                    st.error(f"OpenAI í˜¸ì¶œ ì‹¤íŒ¨: {e}")

    with col_right:
        st.subheader("í†µê³„ / ì›ì‹œ ì‘ë‹µ ë³´ê¸°")
        # KPI (02_data: metric)
        df = pd.DataFrame(st.session_state.logs)
        turns = len(df)
        avg_ms = int(df["t_ms"].mean()) if turns else 0
        total_chars = int(df["chars_out"].sum()) if turns else 0
        c1, c2, c3 = st.columns(3)
        c1.metric("Turns", turns)
        c2.metric("Avg Latency(ms)", avg_ms)
        c3.metric("Out Chars", total_chars)

        # ì›ì‹œ ì‘ë‹µ ë³´ê¸° (02_data: json)
        if turns:
            st.caption("ìµœê·¼ ì‘ë‹µ ì›ë¬¸(JSON ë¹„ìŠ·í•˜ê²Œ ë³´ê¸°)")
            st.json({
                "answer": df.iloc[-1]["answer"],
                "usage": {"tok_in": df.iloc[-1]["tok_in"], "tok_out": df.iloc[-1]["tok_out"]},
                "elapsed_ms": df.iloc[-1]["t_ms"],
                "model": df.iloc[-1]["model"],
            })

        st.divider()
        st.info("ë„ì›€ë§: ì¢Œì¸¡ Domainê³¼ Temperatureë¥¼ ë°”ê¿”ê°€ë©° ì‘ë‹µ ë³€í™”ë¥¼ ê´€ì°°í•˜ì„¸ìš”.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4-2) Logs íƒ­ (02_data: dataframe, download / 04_input widget: ë‹¤ìš´ë¡œë“œ)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with tab_logs:
    st.subheader("ëŒ€í™” ë¡œê·¸")
    df = pd.DataFrame(st.session_state.logs)
    if df.empty:
        st.warning("ì•„ì§ ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤. Chat íƒ­ì—ì„œ ëŒ€í™”ë¥¼ ì‹œì‘í•˜ì„¸ìš”.")
    else:
        st.dataframe(df, use_container_width=True)
        # CSV ë‹¤ìš´ë¡œë“œ
        csv = df.to_csv(index=False).encode("utf-8")
        st.download_button(
            label="CSVë¡œ ë‹¤ìš´ë¡œë“œ",
            data=csv,
            file_name="chat_logs.csv",
            mime="text/csv",
        )

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4-3) Charts íƒ­ (03_chart: Plotlyë¡œ ì‹œê°í™”)
#   - ë°œí™” ê¸¸ì´ / ì‘ë‹µ ì‹œê°„ / (ì˜µì…˜) ê°„ë‹¨ í”¼ë“œë°±
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with tab_charts:
    st.subheader("ì„¸ì…˜ ì§€í‘œ ì‹œê°í™” (Plotly)")

    df = pd.DataFrame(st.session_state.logs)
    if df.empty:
        st.info("ì‹œê°í™”í•  ë¡œê·¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        x = list(range(1, len(df) + 1))

        # ì‘ë‹µ ì‹œê°„ ë¼ì¸
        fig1 = go.Figure(data=go.Scatter(x=x, y=df["t_ms"], mode="lines+markers"))
        fig1.update_layout(title="ì‘ë‹µ ì‹œê°„(ms) ì¶”ì´", xaxis_title="Turn", yaxis_title="ms")
        st.plotly_chart(fig1, use_container_width=True)

        # ì¶œë ¥ ê¸€ì ìˆ˜ ì‚°ì 
        fig2 = go.Figure(data=go.Scatter(x=x, y=df["chars_out"], mode="markers"))
        fig2.update_layout(title="ì¶œë ¥ ê¸¸ì´(ë¬¸ì ìˆ˜)", xaxis_title="Turn", yaxis_title="chars_out")
        st.plotly_chart(fig2, use_container_width=True)

        # (í† í° ì‚¬ìš©ëŸ‰ì´ ìˆìœ¼ë©´) ë§‰ëŒ€
        if "tok_out" in df.columns and df["tok_out"].notna().any():
            fig3 = go.Figure(data=go.Bar(x=x, y=df["tok_out"]))
            fig3.update_layout(title="ì¶œë ¥ í† í° ìˆ˜(ìˆì„ ë•Œ)", xaxis_title="Turn", yaxis_title="tok_out")
            st.plotly_chart(fig3, use_container_width=True)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5) ë³´ì•ˆ/ë°°í¬ ì²´í¬(ë©”ëª¨)
#  - ë¡œì»¬: dotenv(.env) ì‚¬ìš©
#  - Streamlit Cloud ë°°í¬ ì‹œì—ëŠ” Secrets UI ì‚¬ìš© ê°€ëŠ¥(st.secrets) â€” ì—¬ê¸°ì„  í™”ë©´ ë…¸ì¶œë§Œ ë§‰ìŒ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.expander("ğŸ”’ ë³´ì•ˆ/ë°°í¬ ì²´í¬ë¦¬ìŠ¤íŠ¸ (ë©”ëª¨)", expanded=False):
    st.markdown("""
- API KeyëŠ” ì½”ë“œì— ì§ì ‘ ë„£ì§€ ë§ê³  **.env** ë˜ëŠ” ë°°í¬ í™˜ê²½ ë³€ìˆ˜ë¡œ ê´€ë¦¬
- Git ì»¤ë°‹ ê¸ˆì§€(.gitignore)
- Streamlit Cloud ì‚¬ìš© ì‹œ **Secrets** UIì— ë“±ë¡ ê°€ëŠ¥
- ì¸ì¦ì´ í•„ìš”í•˜ë©´ OIDC/í”„ë¡ì‹œ ì•ë‹¨ ê³ ë ¤
""")
