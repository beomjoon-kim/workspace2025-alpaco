# 01_chat_min_stream.py
import os
import streamlit as st
from dotenv import load_dotenv
from openai import OpenAI

# â”€â”€ .env ë¡œë“œ & í´ë¼ì´ì–¸íŠ¸ ì¤€ë¹„ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

st.set_page_config(page_title="Streaming Chat", page_icon="ğŸ”´")
st.title("ğŸ”´ Streaming Chat (OpenAI Responses)")

if not OPENAI_API_KEY:
    st.error("í™˜ê²½ë³€ìˆ˜ OPENAI_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

client = OpenAI(api_key=OPENAI_API_KEY)

# â”€â”€ ëŒ€í™” ìƒíƒœ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "system", "content": "You are a helpful assistant."}]

# ê¸°ì¡´ ëŒ€í™” ë Œë”
for m in st.session_state.messages:
    if m["role"] == "system":
        continue
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

# â”€â”€ ì…ë ¥ & ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ/ì €ì¥
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    with st.chat_message("assistant"):
        placeholder = st.empty()
        collected_chunks = []

        try:
            # Responses API ìŠ¤íŠ¸ë¦¬ë°
            with client.responses.stream(
                model="gpt-4.1-nano",     # í•„ìš”ì— ë”°ë¼ ëª¨ë¸ ë³€ê²½
                input=prompt,
                temperature=0.3,
            ) as stream:
                for event in stream:
                    # ë¶€ë¶„ í† í° ë¸íƒ€ ìˆ˜ì‹ 
                    if event.type == "response.output_text.delta":
                        collected_chunks.append(event.delta)
                        placeholder.markdown("".join(collected_chunks))
                # ëª¨ë“  ì´ë²¤íŠ¸ ì²˜ë¦¬ ì™„ë£Œê¹Œì§€ ëŒ€ê¸°
                stream.until_done()

            answer = "".join(collected_chunks) or "(ì‘ë‹µ ì—†ìŒ)"
            st.session_state.messages.append({"role": "assistant", "content": answer})
        except Exception as e:
            placeholder.error(f"OpenAI ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜: {e}")
