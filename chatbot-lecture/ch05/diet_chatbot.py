# diet_chatbot.py
# Streamlit x OpenAI Responses API - ì‹ë‹¨ ì¶”ì²œ ì±—ë´‡ (ë‹¨ì¼ íŒŒì¼)
import os
import time
import textwrap
import streamlit as st
from dotenv import load_dotenv
from openai import OpenAI

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 0) í™˜ê²½ ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
load_dotenv()
API_KEY = (os.getenv("OPENAI_API_KEY") or "").strip()
if not API_KEY:
    raise RuntimeError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. .envë¥¼ í™•ì¸í•˜ì„¸ìš”.")

client = OpenAI(api_key=API_KEY)

st.set_page_config(page_title="ì‹ë‹¨ ì¶”ì²œ ì±—ë´‡", page_icon="ğŸ¥—", layout="centered")
st.title("ğŸ¥— ì‹ë‹¨ ì¶”ì²œ ì±—ë´‡")
st.caption("ê±´ê°• ëª©í‘œÂ·ì„ í˜¸ë¥¼ ë°˜ì˜í•´ ì‹ë‹¨ì„ ì œì•ˆí•©ë‹ˆë‹¤.")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1) Sidebar: ì˜µì…˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with st.sidebar:
    st.subheader("âš™ï¸ ì¶”ì²œ ì˜µì…˜")
    model = st.selectbox(
        "ëª¨ë¸ ì„ íƒ",
        options=["gpt-4o-mini", "gpt-4o", "gpt-4.1", "gpt-3.5-turbo"],
        index=0,
        help="ê°€ì„±ë¹„ëŠ” gpt-4o-mini ê¶Œì¥"
    )
    meal_type = st.radio("ì‹ì‚¬ ìœ í˜•", ["ì•„ì¹¨", "ì ì‹¬", "ì €ë…"], index=1, horizontal=True)
    target_kcal = st.slider("ëª©í‘œ ì¹¼ë¡œë¦¬ (kcal)", min_value=300, max_value=1200, value=600, step=50)
    diet_pref = st.multiselect(
        "ì‹ë‹¨ ì„ í˜¸/ì œì•½",
        ["ê³ ë‹¨ë°±", "ì €íƒ„ê³ ì§€", "ì§€ì¤‘í•´ì‹", "ì±„ì‹(ë½í† /ì˜¤ë³´ í¬í•¨)", "ë¹„ê±´", "ê¸€ë£¨í… í”„ë¦¬", "ì €ì—¼"],
        default=["ê³ ë‹¨ë°±"]
    )
    allergies = st.text_input("ì•Œë ˆë¥´ê¸°/ê¸°í”¼ ì‹ì¬ë£Œ (ì‰¼í‘œë¡œ êµ¬ë¶„)", placeholder="ì˜ˆ: ë•…ì½©, ìƒˆìš°, ìš°ìœ ")
    cuisine = st.selectbox("ì„ í˜¸í•˜ëŠ” ìŠ¤íƒ€ì¼", ["ì•„ì‹œì•„", "í•œì‹", "ì„œì–‘", "ì§€ì¤‘í•´", "ë¬´ê´€"], index=0)
    servings = st.number_input("ì¸ë¶„(ëª…)", min_value=1, max_value=6, value=1, step=1)
    show_nutri = st.toggle("ì˜ì–‘ì†Œ ìš”ì•½ í¬í•¨", value=True)
    streaming = st.toggle("ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ", value=True, help="ì‹¤ì‹œê°„ìœ¼ë¡œ í† í°ì´ í‘œì‹œë©ë‹ˆë‹¤.")
    st.divider()
    if st.button("ğŸ§¹ ëŒ€í™” ì´ˆê¸°í™”"):
        st.session_state.clear()
        st.experimental_rerun()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 2) ì„¸ì…˜ ìƒíƒœ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if "messages" not in st.session_state:
    st.session_state.messages = []

SYSTEM_GUIDE = textwrap.dedent(f"""
ë„ˆëŠ” ê±´ê°•í•œ ì‹ë‹¨ì„ ì¶”ì²œí•´ì£¼ëŠ” AI ì˜ì–‘ ì½”ì¹˜ì•¼.
ì›ì¹™:
- {meal_type} ê¸°ì¤€ìœ¼ë¡œ {servings}ì¸ë¶„ì„ ì œì•ˆí•  ê²ƒ.
- 1ì¸ë¶„ ê¸°ì¤€ ëª©í‘œ ì¹¼ë¡œë¦¬ëŠ” ì•½ {target_kcal} kcal ì „í›„ë¡œ ë§ì¶œ ê²ƒ(Â±15% í—ˆìš©).
- ì„ í˜¸/ì œì•½: {", ".join(diet_pref) if diet_pref else "íŠ¹ì´ì‚¬í•­ ì—†ìŒ"}.
- ì•Œë ˆë¥´ê¸°/ê¸°í”¼: {allergies or "ì—†ìŒ"}.
- ì„ í˜¸ ìŠ¤íƒ€ì¼: {cuisine}.
- ê°€ëŠ¥í•˜ë©´ ì†ì‰½ê²Œ ì¤€ë¹„ ê°€ëŠ¥í•œ ì¬ë£Œ ì¤‘ì‹¬, ì¡°ë¦¬ë²• ê°„ë‹¨ ìš”ì•½ í¬í•¨.
- í•­ëª© í˜•ì‹: ë©”ë‰´ êµ¬ì„± â†’ ì¬ë£Œ/ë¶„ëŸ‰ â†’ ê°„ë‹¨ ë ˆì‹œí”¼ â†’ ì˜ˆìƒ ì¹¼ë¡œë¦¬ ë° ì˜ì–‘ í¬ì¸íŠ¸{(" â†’ íƒ„/ë‹¨/ì§€/ì‹ì´ì„¬ìœ  í‘œ" if show_nutri else "")}.
""").strip()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 3) ê³¼ê±° ëŒ€í™” ë Œë”ë§
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
for m in st.session_state.messages:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 4) ì‚¬ìš©ì ì…ë ¥ & ëª¨ë¸ í˜¸ì¶œ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
prompt = st.chat_input(f"{meal_type} ì‹ë‹¨ì„ ì¶”ì²œí•´ì¤˜ (ì˜ˆ: í˜„ë¯¸ë°¥+ë‹¨ë°±ì§ˆ+ì•¼ì±„ ìœ„ì£¼)")
if prompt:
    # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ/ì €ì¥
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # ë‹¨ì¼ ë¬¸ìì—´ë¡œ í•©ì„± (Responses APIëŠ” ììœ  í˜•ì‹ input í—ˆìš©)
    composed = f"[SYSTEM]\n{SYSTEM_GUIDE}\n\n[USER]\n{prompt}"

    # í˜¸ì¶œ
    t0 = time.perf_counter()
    try:
        if streaming:
            with st.chat_message("assistant"):
                placeholder = st.empty()
                chunks = []
                with client.responses.stream(
                    model=model,
                    input=composed,
                    temperature=0.4,
                ) as stream:
                    for event in stream:
                        if event.type == "response.output_text.delta":
                            chunks.append(event.delta)
                            placeholder.markdown("".join(chunks))
                    stream.until_done()
                answer = "".join(chunks) if chunks else "(ì‘ë‹µ ì—†ìŒ)"
        else:
            resp = client.responses.create(
                model=model,
                input=composed,
                temperature=0.4,
            )
            answer = getattr(resp, "output_text", None) or str(resp)
            with st.chat_message("assistant"):
                st.markdown(answer)

        # ì‘ë‹µ ì €ì¥
        st.session_state.messages.append({"role": "assistant", "content": answer})

        # ë¶€ê°€ ì•ˆë‚´(ê°„ë‹¨ KPI)
        elapsed_ms = int((time.perf_counter() - t0) * 1000)
        with st.expander("â’¾ ìš”ì²­ ì»¨í…ìŠ¤íŠ¸(ì‹œìŠ¤í…œ ê°€ì´ë“œ)", expanded=False):
            st.code(SYSTEM_GUIDE, language="markdown")
        st.caption(f"â±ï¸ ì‘ë‹µ ì‹œê°„: {elapsed_ms} ms")

    except Exception as e:
        with st.chat_message("assistant"):
            st.error(f"OpenAI í˜¸ì¶œ ì‹¤íŒ¨: {e}")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 5) í‘¸í„°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.markdown("---")
st.caption("ğŸ”’ API KeyëŠ” .envë¡œ ê´€ë¦¬í•˜ì„¸ìš”. | âš ï¸ ê±´ê°• ê´€ë ¨ ì •ë³´ëŠ” ì°¸ê³ ìš©ì´ë©°, ê°œì¸ ìƒí™©ì— ë”°ë¼ ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì„¸ìš”.")
